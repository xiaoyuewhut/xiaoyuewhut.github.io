<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>文献阅读：ST-P3: End-to-End Vision-Based Autonomous Driving via Spatial-Temporal Feature Learning | xiaoyue的博客</title><meta name="author" content="Xiao yue"><meta name="copyright" content="Xiao yue"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="引言  Hu S, Chen L, Wu P, et al. St-p3: End-to-end vision-based autonomous driving via spatial-temporal feature learning[C]&#x2F;&#x2F;European Conference on Computer Vision. Cham: Springer Nature Switzerland, 20">
<meta property="og:type" content="article">
<meta property="og:title" content="文献阅读：ST-P3: End-to-End Vision-Based Autonomous Driving via Spatial-Temporal Feature Learning">
<meta property="og:url" content="http://example.com/2025/12/03/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9AST-P3-End-to-End-Vision-Based-Autonomous-Driving-via-Spatial-Temporal-Feature-Learning/index.html">
<meta property="og:site_name" content="xiaoyue的博客">
<meta property="og:description" content="引言  Hu S, Chen L, Wu P, et al. St-p3: End-to-end vision-based autonomous driving via spatial-temporal feature learning[C]&#x2F;&#x2F;European Conference on Computer Vision. Cham: Springer Nature Switzerland, 20">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/img/butterfly-icon.png">
<meta property="article:published_time" content="2025-12-03T07:42:21.000Z">
<meta property="article:modified_time" content="2025-12-03T08:59:02.725Z">
<meta property="article:author" content="Xiao yue">
<meta property="article:tag" content="智能驾驶">
<meta property="article:tag" content="端到端">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/butterfly-icon.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "文献阅读：ST-P3: End-to-End Vision-Based Autonomous Driving via Spatial-Temporal Feature Learning",
  "url": "http://example.com/2025/12/03/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9AST-P3-End-to-End-Vision-Based-Autonomous-Driving-via-Spatial-Temporal-Feature-Learning/",
  "image": "http://example.com/img/butterfly-icon.png",
  "datePublished": "2025-12-03T07:42:21.000Z",
  "dateModified": "2025-12-03T08:59:02.725Z",
  "author": [
    {
      "@type": "Person",
      "name": "Xiao yue",
      "url": "http://example.com"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://example.com/2025/12/03/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9AST-P3-End-to-End-Vision-Based-Autonomous-Driving-via-Spatial-Temporal-Feature-Learning/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=5.5.2"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@7.1.0/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@6.1.4/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          const mediaQueryDark = window.matchMedia('(prefers-color-scheme: dark)')
          const mediaQueryLight = window.matchMedia('(prefers-color-scheme: light)')

          if (theme === undefined) {
            if (mediaQueryLight.matches) activateLightMode()
            else if (mediaQueryDark.matches) activateDarkMode()
            else {
              const hour = new Date().getHours()
              const isNight = hour <= 6 || hour >= 18
              isNight ? activateDarkMode() : activateLightMode()
            }
            mediaQueryDark.addEventListener('change', () => {
              if (saveToLocal.get('theme') === undefined) {
                e.matches ? activateDarkMode() : activateLightMode()
              }
            })
          } else {
            theme === 'light' ? activateLightMode() : activateDarkMode()
          }
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":true},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.12.0/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '文献阅读：ST-P3: End-to-End Vision-Based Autonomous Driving via Spatial-Temporal Feature Learning',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 8.1.1"></head><body><div id="web_bg" style="background-image: url(https://api.dujin.org/bing/1920.php);"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/butterfly-icon.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/ loading='lazy'></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">25</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">26</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/categories/%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6/"><i class="fa-fw fas fa-robot"></i><span> 自动驾驶</span></a></div><div class="menus_item"><a class="site-page" href="/categories/%E6%96%B0%E8%83%BD%E6%BA%90%E6%8A%80%E6%9C%AF/"><i class="fa-fw fas fa-solar-panel"></i><span> 新能源技术</span></a></div><div class="menus_item"><a class="site-page" href="/categories/%E8%BD%A6%E8%BE%86%E5%8A%A8%E5%8A%9B%E5%AD%A6/"><i class="fa-fw fas fa-car-side"></i><span> 车辆动力学</span></a></div><div class="menus_item"><a class="site-page" href="/categories/%E6%8E%A7%E5%88%B6/"><i class="fa-fw fas fa-cogs"></i><span> 控制</span></a></div><div class="menus_item"><a class="site-page" href="/categories/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB/"><i class="fa-fw fas fa-book-open"></i><span> 文献阅读</span></a></div><div class="menus_item"><a class="site-page" href="/categories/%E5%85%B6%E4%BB%96/"><i class="fa-fw fas fa-ellipsis-h"></i><span> 其他</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-user"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://cn.bing.com/th?id=OHR.AspensColorado_ZH-CN0132780533_1920x1080.jpg&amp;rf=LaDigue_1920x1080.jpg&amp;pid=hp);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">xiaoyue的博客</span></a><a class="nav-page-title" href="/"><span class="site-name">文献阅读：ST-P3: End-to-End Vision-Based Autonomous Driving via Spatial-Temporal Feature Learning</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  返回首页</span></span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/categories/%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6/"><i class="fa-fw fas fa-robot"></i><span> 自动驾驶</span></a></div><div class="menus_item"><a class="site-page" href="/categories/%E6%96%B0%E8%83%BD%E6%BA%90%E6%8A%80%E6%9C%AF/"><i class="fa-fw fas fa-solar-panel"></i><span> 新能源技术</span></a></div><div class="menus_item"><a class="site-page" href="/categories/%E8%BD%A6%E8%BE%86%E5%8A%A8%E5%8A%9B%E5%AD%A6/"><i class="fa-fw fas fa-car-side"></i><span> 车辆动力学</span></a></div><div class="menus_item"><a class="site-page" href="/categories/%E6%8E%A7%E5%88%B6/"><i class="fa-fw fas fa-cogs"></i><span> 控制</span></a></div><div class="menus_item"><a class="site-page" href="/categories/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB/"><i class="fa-fw fas fa-book-open"></i><span> 文献阅读</span></a></div><div class="menus_item"><a class="site-page" href="/categories/%E5%85%B6%E4%BB%96/"><i class="fa-fw fas fa-ellipsis-h"></i><span> 其他</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-user"></i><span> 关于</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">文献阅读：ST-P3: End-to-End Vision-Based Autonomous Driving via Spatial-Temporal Feature Learning</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-12-03T07:42:21.000Z" title="发表于 2025-12-03 15:42:21">2025-12-03</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-12-03T08:59:02.725Z" title="更新于 2025-12-03 16:59:02">2025-12-03</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB/">文献阅读</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h1>引言</h1>
<blockquote>
<p>Hu S, Chen L, Wu P, et al. St-p3: End-to-end vision-based autonomous driving via spatial-temporal feature learning[C]//European Conference on Computer Vision. Cham: Springer Nature Switzerland, 2022: 533-549.</p>
</blockquote>
<h2 id="为什么做这个研究？">为什么做这个研究？</h2>
<p>作者想解决现有自动驾驶系统的一个痛点：传统方法把感知、预测、规划拆成独立模块串行处理，像流水线一样，前一个模块出错后一个就跟着错。而端到端方法虽然能联合优化，但现有研究要么依赖昂贵的激光雷达，要么就是&quot;黑箱&quot;模型不够透明。</p>
<h2 id="核心问题是什么？">核心问题是什么？</h2>
<p>纯视觉方案如何把2D图像转换成3D的BEV？</p>
<p>这个转换需要深度信息，而<strong>深度估计本身就很难</strong>。更重要的是，随着时间推移，车辆移动会导致<strong>特征对齐问题</strong>——过去的画面和当前画面对不上，几何信息容易丢失。</p>
<h3 id="为什么深度估计很难？">为什么深度估计很难？</h3>
<ol>
<li>
<p><strong>几何本质的歧义</strong><br>
单张2D图像对应着无限多个可能的3D场景。想象一下：一张照片中一个5米高的路灯和远处一个50米高的塔楼，如果只看像素尺寸和纹理，它们可能看起来完全一样。这是因为<strong>相机无法区分&quot;大尺寸物体&quot;和&quot;近距离的小物体&quot;</strong>。</p>
</li>
<li>
<p><strong>监督信号稀缺</strong><br>
比如即使去用激光雷达，稀疏点云的覆盖度也不高，还容易受到遮挡。</p>
</li>
<li>
<p><strong>自动驾驶场景本身对深度要求高</strong></p>
</li>
<li>
<p><strong>泛化能力受到很多因素的影响</strong></p>
</li>
</ol>
<h3 id="什么是特征对齐问题？">什么是特征对齐问题？</h3>
<p>想象你的车有6个摄像头（前后左右+两个斜角），每0.5秒拍一张照片。你的任务是把这6张照片拼成一个俯视图（BEV），看清楚周围50米内所有车和人的位置。</p>
<p><strong>特征对齐问题就是：如何把不同相机、不同时间拍的&quot;碎片&quot;拼到同一张正确的地图上？</strong></p>
<p>所以首先遇到的问题就是<strong>空间对齐</strong>，如果直接把6个画面塞进神经网络，模型会疯掉：这个到底是同一辆车，还是6辆不同的车？</p>
<p>所以一般操作是把所有相机的像素先&quot;反投影&quot;到3D空间（每个像素变成一条射线），再统一到当前时刻的ego坐标系（以车中心为原点的3D世界）。</p>
<p>第二个问题又来了：车本身是要运动的，感知对象也可能在运动，怎么去进行<strong>时序对齐</strong>呢？</p>
<p>传统的做法是每个 frame 都先变换到当前 bev，再做拼接，再做 3D 卷积。但是<strong>先转成BEV再拼接，高度信息已经丢了（从3D压成2D），动态物体没对齐。</strong></p>
<blockquote>
<p>本文的ST-P3的解决方案：先对齐，再BEV。</p>
</blockquote>
<p>在3D空间里，把过去所有帧的特征搬到现在车的坐标系下，像积木一样堆起来，最后再&quot;压扁&quot;成BEV图。</p>
<pre><code class="highlight mermaid">graph LR
    frame1[历史帧] --&gt; align
    frame2[历史帧] --&gt; align
    frame3[当前帧] --&gt; align
    
    align[对齐到当前3D坐标系] --&gt; fuse
    
    fuse[3D空间累加融合] --&gt; bev
    
    bev[池化 → BEV特征]</code></pre>
<h2 id="提出了什么解决方案？">提出了什么解决方案？</h2>
<p>提出的ST-P3方案有三个创新点：</p>
<ol>
<li>感知模块：在转换到BEV之前，先把所有历史帧的3D特征对齐到当前车辆坐标系下累加，保留完整的几何信息</li>
<li>预测模块：设计双路径结构，一条路径处理未来不确定性（像人脑想象多种可能），另一条学习历史运动规律，两者互补</li>
<li>规划模块：用GRU网络&quot;精修&quot;轨迹，专门处理红绿灯等视觉细节，不靠高清地图</li>
</ol>
<p><img src="https://cdn.jsdelivr.net/gh/xiaoyuewhut/image@main/20251203160940235.png" alt="" loading='lazy'></p>
<h1>啊啊啊啊啊</h1>
<blockquote>
<p>感知和预测直接忽略，不想看</p>
</blockquote>
<h1>规划</h1>
<p>ST-P3的规划模块最大的亮点是：<strong>在显式采样框架下，用学习成本+GRU精修实现了无HD地图的鲁棒规划</strong>。</p>
<pre><code class="highlight mermaid">graph TD
    A[状态机] --&gt; B[轨迹采样]
    C[BEV特征] --&gt; D[成本场生成]
    B --&gt; E[轨迹评估]
    D --&gt; E
    F[前视摄像头特征] --&gt; G[GRU精修]
    E --&gt; H[最优轨迹τ*]
    H --&gt; G
    G --&gt; I[最终轨迹τ*_o]</code></pre>
<h2 id="输入">输入</h2>
<ul>
<li>在无图的情况下，来自状态机的 high level 命令只是直行、左转、右转这样子，所以只是一个粗粒度命令告诉规划器&quot;大概往哪儿走&quot;</li>
<li>BEV预测结果：车辆/行人占位图、可行驶区域、车道线</li>
<li>自车状态：速度、位姿</li>
<li>前视摄像头特征：用于红绿灯识别</li>
</ul>
<h2 id="轨迹采样">轨迹采样</h2>
<p>给定自车状态<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>v</mi><mo separator="true">,</mo><msub><mi>δ</mi><mn>0</mn></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(v,\delta_0)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>，采样器基于自行车模型在速度-曲率空间做网格搜索：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>τ</mi><mo>=</mo><mtext>BicycleModel</mtext><mrow><mo fence="true">(</mo><mi>v</mi><mo>+</mo><mi mathvariant="normal">Δ</mi><mi>v</mi><mo separator="true">,</mo><msub><mi>δ</mi><mn>0</mn></msub><mo>+</mo><mi mathvariant="normal">Δ</mi><mi>δ</mi><mo separator="true">,</mo><mi>T</mi><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\tau = \text{BicycleModel} \left( v+\Delta v, \delta_0 + \Delta \delta, T \right)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.1132em;">τ</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">BicycleModel</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">Δ</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03785em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord">Δ</span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mclose delimcenter" style="top:0em;">)</span></span></span></span></span></span></p>
<p>一般会采样2000条候选轨迹的样子，然后再过成本评估，选一条成本最小的轨迹。</p>
<h2 id="创新点-1：混合成本函数">创新点 1：混合成本函数</h2>
<p>成本函数由三部分组成，不搞纯黑盒：</p>
<p class='katex-block'><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>τ</mi><mo separator="true">,</mo><mi>o</mi><mo separator="true">,</mo><mi>m</mi><mo separator="true">;</mo><mi>w</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mi>f</mi><mn>0</mn></msub><mo stretchy="false">(</mo><mi>τ</mi><mo separator="true">,</mo><mi>o</mi><mo separator="true">,</mo><mi>m</mi><mo separator="true">;</mo><msub><mi>w</mi><mn>0</mn></msub><mo stretchy="false">)</mo><mo>+</mo><msub><mi>f</mi><mi>v</mi></msub><mo stretchy="false">(</mo><mi>τ</mi><mo separator="true">;</mo><msub><mi>w</mi><mi>v</mi></msub><mo stretchy="false">)</mo><mo>+</mo><msub><mi>f</mi><mi>τ</mi></msub><mo stretchy="false">(</mo><mi>τ</mi><mo separator="true">;</mo><msub><mi>w</mi><mi>τ</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(\tau, o, m; w) = f_0(\tau, o, m; w_0) + f_v(\tau; w_v) + f_{\tau}(\tau; w_{\tau})
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.1132em;">τ</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">o</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">m</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.1132em;">τ</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">o</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">m</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.1132em;">τ</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.1132em;">τ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.1132em;">τ</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.1132em;">τ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p>
<ul>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">f_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>：安全规则成本（手工设计，可解释），相当于先验知识。</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mi>v</mi></msub></mrow><annotation encoding="application/x-tex">f_v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>：学习成本场（数据驱动，泛化性强），因为预测head会输出一个Cost Volume：每个位置一个代价值，所以相当于让网络自己学&quot;哪些区域危险但规则写不出来&quot;。</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mi>r</mi></msub></mrow><annotation encoding="application/x-tex">f_r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.10764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>：舒适性成本</li>
</ul>
<h2 id="创新点-2：GRU精修单元">创新点 2：GRU精修单元</h2>
<p>以前的工作里，初始轨迹只依赖BEV，但BEV对远距离/小目标的红绿灯识别不准。因为BEV投影后红绿灯像素就几个点，容易漏检或误检。</p>
<blockquote>
<p>不关心，略过略过</p>
</blockquote>
<h2 id="创新点-3：无HD地图的采样策略">创新点 3：无HD地图的采样策略</h2>
<p>就是上面说的，既然没有HD地图的路由线，就用离散命令粗粒度引导：</p>
<ul>
<li>直行：采样器生成前向轨迹簇（曲率小）</li>
<li>左转：采样器生成左曲率轨迹簇（初始<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>δ</mi></mrow><annotation encoding="application/x-tex">\delta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span></span></span></span>为负）</li>
<li>右转：采样器生成右曲率轨迹簇（初始<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>δ</mi></mrow><annotation encoding="application/x-tex">\delta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span></span></span></span>为正）</li>
</ul>
<p>(但实际操作可能不会这么严格的正负，只是如果左转，那转角的右边界就会小很多，左边界会被拓宽)</p>
<p>另外的就是让感知模块在线生成&quot;伪地图&quot;，然后采样器把这些语义分割结果当作约束。也不讨论。</p>
<h1>总结</h1>
<p>感知看不懂，实时性没提，感觉不适合高速和高阶智驾，无图方案在舒适性上仍落后HD地图方案，对乘用车体验是硬伤。</p>
<p>也没那么端到端，看半天发现重点在 bev 的感知，妈的。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="http://example.com">Xiao yue</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2025/12/03/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9AST-P3-End-to-End-Vision-Based-Autonomous-Driving-via-Spatial-Temporal-Feature-Learning/">http://example.com/2025/12/03/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9AST-P3-End-to-End-Vision-Based-Autonomous-Driving-via-Spatial-Temporal-Feature-Learning/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="http://example.com" target="_blank">xiaoyue的博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%99%BA%E8%83%BD%E9%A9%BE%E9%A9%B6/">智能驾驶</a><a class="post-meta__tags" href="/tags/%E7%AB%AF%E5%88%B0%E7%AB%AF/">端到端</a></div><div class="post-share"><div class="social-share" data-image="/img/butterfly-icon.png" data-sites="facebook,x,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2025/12/05/ADAS-%E4%BC%A0%E6%84%9F%E5%99%A8%E5%B8%83%E7%BD%AE/" title="ADAS 传感器布置"><img class="cover" src="https://cdn.jsdelivr.net/gh/xiaoyuewhut/image@main/20251205114331669.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post" loading='lazy'><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">ADAS 传感器布置</div></div><div class="info-2"><div class="info-item-1">传感器种类  概括一下：    传感器类型 主要功能 典型应用 工作频率/范围     摄像头 图像识别、物体分类 车道偏离预警、交通标志识别、行人检测、盲点监测、360°环视 前视(150m)、环视(20m)   毫米波雷达 距离、速度测量 自适应巡航(ACC)、自动紧急制动(AEB)、盲点监测(BSD)、变道辅助(LCA) 77GHz（长距离）、24GHz（短距离）   激光雷达(LiDAR) 高精度三维环境感知 障碍物检测、道路识别、导航规划 长距离高精度扫描   超声波雷达 近距离障碍物探测 倒车雷达、自动泊车(APA)、低速碰撞预警 短距离（通常&lt;5m）     一般来说，汽车都会装以下几个传感器：     传感器 数量     前视摄像头 1   77GHz 前向毫米波雷达 1   24GHz 侧向毫米波雷达 4   超声波雷达 12   环视鱼眼摄像头 4    为什么前向毫米波雷达采用77GHz、侧向采用24GHz？ 主要是基于探测距离、精度需求、成本控制和安装位置等因素的综合考量。  目前77GHz也正逐步向侧向应用渗透  前向用77GHz的原因：   探...</div></div></div></a><a class="pagination-related" href="/2025/12/03/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9ASurvey-of-Technology-in-Autonomous-Valet-Parking-System/" title="文献阅读：Survey of Technology in Autonomous Valet Parking System"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">文献阅读：Survey of Technology in Autonomous Valet Parking System</div></div><div class="info-2"><div class="info-item-1">引言  Jo Y, Ha J, Hwang S. Survey of technology in autonomous valet parking system[J]. International Journal of Automotive Technology, 2023, 24(6): 1577-1587.  代客泊车（Valet parking）是法语“valet”（意为代泊）和英语“parking”组成的复合词，指的是由管理人员代替车主泊车的服务。自动代客泊车（AVP）系统将代客泊车与自动驾驶车辆相结合，这项技术能让车辆自动行驶到停车位完成泊车，并且在泊车后用户召唤时将车辆移动到指定位置。通常情况下，该系统无需人工操作就能在行驶和泊车场景中对车辆进行控制。 一般AVP的流程如下：  其中搜索路径需要考虑很多约束：车辆的转弯半径、转向速度、障碍物、停车位类型。 Return Driving Process 就是将车辆移动到用户可以再次上车的地方。通过追踪先前流程中的路径来实现。 搜索过程 搜索路径的基础是车辆自身以及周围物体的定位，比如：  使用GPS+IMU来确定车辆的速...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/11/25/%E6%99%BA%E9%A9%BE%E6%96%B9%E6%A1%88%E5%A4%A7%E6%A6%82/" title="智驾方案大概"><img class="cover" src="https://cdn.jsdelivr.net/gh/xiaoyuewhut/image@main/20251125113221668.png" alt="cover" loading='lazy'><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-11-25</div><div class="info-item-2">智驾方案大概</div></div><div class="info-2"><div class="info-item-1">感知类辅助功能 Perception Aids 这些主要是“告诉驾驶员情况”，不主动控制车辆。其实更侧重于对前向的感知，全向也有。  FCW — Forward Collision Warning 前向碰撞预警 PCW — Pedestrian Collision Warning 行人碰撞预警 AEB-Warning — 自动紧急制动警告 LDW — Lane Departure Warning 车道偏离预警 BSD — Blind Spot Detection 盲区监测 BSW — Blind Spot Warning 盲区预警 LCA-W — Lane Change Assist Warning 换道辅助预警 RCW — Rear Collision Warning 后碰撞预警 CTA — Cross Traffic Alert 横向来车预警（R-CTA / F-CTA） IHC / AHB — Intelligent High Beam / Auto High Beam 自动远光切换 TSR — Traffic Sign Recognition 交通标志识别 DAW — D...</div></div></div></a><a class="pagination-related" href="/2025/11/21/%E8%87%AA%E9%80%82%E5%BA%94%E5%B7%A1%E8%88%AA%E6%8E%A7%E5%88%B6ACC%E5%8A%9F%E8%83%BD%E8%A7%84%E8%8C%83/" title="自适应巡航控制ACC功能规范"><img class="cover" src="https://cdn.jsdelivr.net/gh/xiaoyuewhut/image@main/20251121134725596.png" alt="cover" loading='lazy'><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-11-21</div><div class="info-item-2">自适应巡航控制ACC功能规范</div></div><div class="info-2"><div class="info-item-1">从工程实现看L2级纵向控制 将从系统架构、状态机设计、人机交互策略等维度，剖析ACC的工程实现精髓。 系统架构：多传感器协同 ACC系统的感知层采用&quot;视觉+雷达&quot;的异构冗余方案： 传感器配置矩阵  前视摄像头：通过LVDS接口接入，分辨率1280×960，综合视距150m+，主要负责车道线识别和目标分类 前向毫米波雷达：77GHz频段，160m探测距离，±45°水平视场角，提供高鲁棒性的距离与速度测量 超声波雷达：12探头方案，私有CAN通信，主要用于低速Stop&amp;Go场景的近距离补盲  执行路径设计 系统采用 “ADAS控制器→ESP→VCU” 的纵向控制链路。ADAS通过私有CAN发送目标加速度请求（ADAS_VLCAxTarAim），ESP的VLC（Vehicle Longitudinal Control）模块负责扭矩仲裁，最终通过ESP_MotorTorqReq信号驱动VCU实现加减速。这种分层架构将控制算法与车辆动力学解耦，提升了跨平台移植性。 核心信号带宽  感知刷新率：30Hz（摄像头与雷达融合周期） CAN总线负载：500kbps，采用...</div></div></div></a><a class="pagination-related" href="/2025/11/27/AVM%E4%B8%8B%E7%BA%BF%E6%A0%87%E5%AE%9A%E6%B5%81%E7%A8%8B/" title="AVM下线标定流程"><img class="cover" src="https://cdn.jsdelivr.net/gh/xiaoyuewhut/image@main/20251127140956769.png" alt="cover" loading='lazy'><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-11-27</div><div class="info-item-2">AVM下线标定流程</div></div><div class="info-2"><div class="info-item-1">简单介绍 AVM （Around View Monitor，环视系统）环视系统通过安装在车身前、后、左、右的四个鱼眼摄像头，通过图像处理算法拼接成一幅 360° 的鸟瞰图（Bird’s Eye View, BEV）。然而，摄像头在总装过程中必然存在 6 自由度的安装误差。从数学原理、标定场搭建、算法流程及工程实践四个维度，详细剖析 AVM 的下线标定（EOL）技术。  为什么需要 EOL 标定？ 在理想的 CAD 模型中，我们知道每个摄像头相对于车身坐标系的精确位置。但在实际生产线上，安装公差会导致以下问题：   平移误差：摄像头位置偏移。   旋转误差：摄像头拍摄角度倾斜（如 Pitch/Roll/Yaw 偏差）。   如果不进行标定，直接使用理论参数进行投影拼接，会导致地面标线断裂、重影，甚至障碍物位置判断错误。EOL 标定的核心目标，就是求解摄像头坐标系到车身坐标系的真实变换矩阵。 想象一下手机拍照，四个角装了四个超广角镜头，要把它们拼成一张完美的俯视图。但工人安装时，摄像头可能歪了1毫米、斜了0.5度。标定就是解决&quot;歪了怎么办&quot;的问题。 数学模型基础 ...</div></div></div></a><a class="pagination-related" href="/2025/12/01/LCC%E5%8A%9F%E8%83%BD%E8%A7%84%E8%8C%83/" title="车道居中控制 LCC"><img class="cover" src="https://cdn.jsdelivr.net/gh/xiaoyuewhut/image@main/20251121134725596.png" alt="cover" loading='lazy'><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-12-01</div><div class="info-item-2">车道居中控制 LCC</div></div><div class="info-2"><div class="info-item-1">引言 LCC，Lane Cruise Control，车道巡航辅助，也有叫车道车道居中控制的，是一种横向辅助功能。在车辆行驶过程中，系统利用摄像头探测车道线，计算车辆在车道内的位置，并通过控制 EPS 施加转向力矩，使车辆持续保持在当前车道的中心位置行驶。  有些LCC会跟随驾驶员打转向灯自动变道，但是这里不讨论，单纯的车道居中并不具备ALC功能。  参考资料  岚图ADS LCC使用手册 理想汽车全场景辅助驾驶（LCC） 小鹏汽车车道居中辅助（LCC）快速上手指南 享界 S9 增程版使用说明书   注意：与 ACC 不同，ACC 控制油门/刹车，LCC 控制方向盘。LCC 必须在 ACC 激活的前提下才能工作（除部分低速排队辅助场景外）。  相比于ACC更加高级，却低于NOA。    功能 全称 核心作用 控制维度 技术复杂度     ACC 自适应巡航 自动跟车，保持安全车距 仅纵向（速度/距离） 基础   LCC 车道居中控制 保持车辆在车道中央行驶 纵向+横向（方向盘微调） 中等   NOA 导航辅助驾驶 按导航路径自动变道、进出匝道 纵向+横向+路径决策 高阶     ...</div></div></div></a><a class="pagination-related" href="/2025/12/03/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9ASurvey-of-Technology-in-Autonomous-Valet-Parking-System/" title="文献阅读：Survey of Technology in Autonomous Valet Parking System"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-12-03</div><div class="info-item-2">文献阅读：Survey of Technology in Autonomous Valet Parking System</div></div><div class="info-2"><div class="info-item-1">引言  Jo Y, Ha J, Hwang S. Survey of technology in autonomous valet parking system[J]. International Journal of Automotive Technology, 2023, 24(6): 1577-1587.  代客泊车（Valet parking）是法语“valet”（意为代泊）和英语“parking”组成的复合词，指的是由管理人员代替车主泊车的服务。自动代客泊车（AVP）系统将代客泊车与自动驾驶车辆相结合，这项技术能让车辆自动行驶到停车位完成泊车，并且在泊车后用户召唤时将车辆移动到指定位置。通常情况下，该系统无需人工操作就能在行驶和泊车场景中对车辆进行控制。 一般AVP的流程如下：  其中搜索路径需要考虑很多约束：车辆的转弯半径、转向速度、障碍物、停车位类型。 Return Driving Process 就是将车辆移动到用户可以再次上车的地方。通过追踪先前流程中的路径来实现。 搜索过程 搜索路径的基础是车辆自身以及周围物体的定位，比如：  使用GPS+IMU来确定车辆的速...</div></div></div></a><a class="pagination-related" href="/2025/12/05/ADAS-%E4%BC%A0%E6%84%9F%E5%99%A8%E5%B8%83%E7%BD%AE/" title="ADAS 传感器布置"><img class="cover" src="https://cdn.jsdelivr.net/gh/xiaoyuewhut/image@main/20251205114331669.png" alt="cover" loading='lazy'><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-12-05</div><div class="info-item-2">ADAS 传感器布置</div></div><div class="info-2"><div class="info-item-1">传感器种类  概括一下：    传感器类型 主要功能 典型应用 工作频率/范围     摄像头 图像识别、物体分类 车道偏离预警、交通标志识别、行人检测、盲点监测、360°环视 前视(150m)、环视(20m)   毫米波雷达 距离、速度测量 自适应巡航(ACC)、自动紧急制动(AEB)、盲点监测(BSD)、变道辅助(LCA) 77GHz（长距离）、24GHz（短距离）   激光雷达(LiDAR) 高精度三维环境感知 障碍物检测、道路识别、导航规划 长距离高精度扫描   超声波雷达 近距离障碍物探测 倒车雷达、自动泊车(APA)、低速碰撞预警 短距离（通常&lt;5m）     一般来说，汽车都会装以下几个传感器：     传感器 数量     前视摄像头 1   77GHz 前向毫米波雷达 1   24GHz 侧向毫米波雷达 4   超声波雷达 12   环视鱼眼摄像头 4    为什么前向毫米波雷达采用77GHz、侧向采用24GHz？ 主要是基于探测距离、精度需求、成本控制和安装位置等因素的综合考量。  目前77GHz也正逐步向侧向应用渗透  前向用77GHz的原因：   探...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/butterfly-icon.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/ loading='lazy'></div><div class="author-info-name">Xiao yue</div><div class="author-info-description">🚗 智能驾驶系统工程师</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">25</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">26</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xiaoyuewhut"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="mailto:xiaoyuewhut@whut.edu.cn" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">图片加载不出来需要挂vpn</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">引言</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E5%81%9A%E8%BF%99%E4%B8%AA%E7%A0%94%E7%A9%B6%EF%BC%9F"><span class="toc-number">1.1.</span> <span class="toc-text">为什么做这个研究？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83%E9%97%AE%E9%A2%98%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="toc-number">1.2.</span> <span class="toc-text">核心问题是什么？</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E6%B7%B1%E5%BA%A6%E4%BC%B0%E8%AE%A1%E5%BE%88%E9%9A%BE%EF%BC%9F"><span class="toc-number">1.2.1.</span> <span class="toc-text">为什么深度估计很难？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E7%89%B9%E5%BE%81%E5%AF%B9%E9%BD%90%E9%97%AE%E9%A2%98%EF%BC%9F"><span class="toc-number">1.2.2.</span> <span class="toc-text">什么是特征对齐问题？</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%EF%BC%9F"><span class="toc-number">1.3.</span> <span class="toc-text">提出了什么解决方案？</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">2.</span> <span class="toc-text">啊啊啊啊啊</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">3.</span> <span class="toc-text">规划</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BE%93%E5%85%A5"><span class="toc-number">3.1.</span> <span class="toc-text">输入</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BD%A8%E8%BF%B9%E9%87%87%E6%A0%B7"><span class="toc-number">3.2.</span> <span class="toc-text">轨迹采样</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%9B%E6%96%B0%E7%82%B9-1%EF%BC%9A%E6%B7%B7%E5%90%88%E6%88%90%E6%9C%AC%E5%87%BD%E6%95%B0"><span class="toc-number">3.3.</span> <span class="toc-text">创新点 1：混合成本函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%9B%E6%96%B0%E7%82%B9-2%EF%BC%9AGRU%E7%B2%BE%E4%BF%AE%E5%8D%95%E5%85%83"><span class="toc-number">3.4.</span> <span class="toc-text">创新点 2：GRU精修单元</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%9B%E6%96%B0%E7%82%B9-3%EF%BC%9A%E6%97%A0HD%E5%9C%B0%E5%9B%BE%E7%9A%84%E9%87%87%E6%A0%B7%E7%AD%96%E7%95%A5"><span class="toc-number">3.5.</span> <span class="toc-text">创新点 3：无HD地图的采样策略</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">4.</span> <span class="toc-text">总结</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/12/10/%E2%80%9C%E4%BD%BF%E7%94%A8%E9%9D%9E%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%E6%B1%82%E8%A7%A3%E5%8F%82%E8%80%83%E7%82%B9%E2%80%9C/" title="使用非线性模型求解参考点">使用非线性模型求解参考点</a><time datetime="2025-12-10T03:26:13.000Z" title="发表于 2025-12-10 11:26:13">2025-12-10</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/12/08/%E8%BD%AE%E6%AF%82%E7%94%B5%E6%9C%BA%E7%9A%84%E5%8F%8D%E5%8A%9B%E7%9F%A9/" title="轮毂电机的反力矩">轮毂电机的反力矩</a><time datetime="2025-12-08T05:49:35.000Z" title="发表于 2025-12-08 13:49:35">2025-12-08</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/12/05/ADAS-%E4%BC%A0%E6%84%9F%E5%99%A8%E5%B8%83%E7%BD%AE/" title="ADAS 传感器布置"><img src="https://cdn.jsdelivr.net/gh/xiaoyuewhut/image@main/20251205114331669.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="ADAS 传感器布置"/ loading='lazy'></a><div class="content"><a class="title" href="/2025/12/05/ADAS-%E4%BC%A0%E6%84%9F%E5%99%A8%E5%B8%83%E7%BD%AE/" title="ADAS 传感器布置">ADAS 传感器布置</a><time datetime="2025-12-05T03:39:58.000Z" title="发表于 2025-12-05 11:39:58">2025-12-05</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/12/03/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9AST-P3-End-to-End-Vision-Based-Autonomous-Driving-via-Spatial-Temporal-Feature-Learning/" title="文献阅读：ST-P3: End-to-End Vision-Based Autonomous Driving via Spatial-Temporal Feature Learning">文献阅读：ST-P3: End-to-End Vision-Based Autonomous Driving via Spatial-Temporal Feature Learning</a><time datetime="2025-12-03T07:42:21.000Z" title="发表于 2025-12-03 15:42:21">2025-12-03</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/12/03/%E6%96%87%E7%8C%AE%E9%98%85%E8%AF%BB%EF%BC%9ASurvey-of-Technology-in-Autonomous-Valet-Parking-System/" title="文献阅读：Survey of Technology in Autonomous Valet Parking System">文献阅读：Survey of Technology in Autonomous Valet Parking System</a><time datetime="2025-12-03T03:15:01.000Z" title="发表于 2025-12-03 11:15:01">2025-12-03</time></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;&nbsp;2025 By Xiao yue</span><span class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 8.1.1</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.5.2</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=5.5.2"></script><script src="/js/main.js?v=5.5.2"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@6.1.4/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>(async () => {
  const showKatex = () => {
    document.querySelectorAll('#article-container .katex').forEach(el => el.classList.add('katex-show'))
  }

  if (!window.katex_js_css) {
    window.katex_js_css = true
    await btf.getCSS('https://cdn.jsdelivr.net/npm/katex@0.16.25/dist/katex.min.css')
    if (true) {
      await btf.getScript('https://cdn.jsdelivr.net/npm/katex@0.16.25/dist/contrib/copy-tex.min.js')
    }
  }

  showKatex()
})()</script><script>(() => {
  const runMermaid = ele => {
    window.loadMermaid = true
    const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

    ele.forEach((item, index) => {
      const mermaidSrc = item.firstElementChild
      const config = mermaidSrc.dataset.config ? JSON.parse(mermaidSrc.dataset.config) : {}
      if (!config.theme) {
        config.theme = theme
      }
      const mermaidThemeConfig = `%%{init: ${JSON.stringify(config)}}%%\n`
      const mermaidID = `mermaid-${index}`
      const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent

      const renderFn = mermaid.render(mermaidID, mermaidDefinition)
      const renderMermaid = svg => {
        mermaidSrc.insertAdjacentHTML('afterend', svg)
      }

      // mermaid v9 and v10 compatibility
      typeof renderFn === 'string' ? renderMermaid(renderFn) : renderFn.then(({ svg }) => renderMermaid(svg))
    })
  }

  const codeToMermaid = () => {
    const codeMermaidEle = document.querySelectorAll('pre > code.mermaid')
    if (codeMermaidEle.length === 0) return

    codeMermaidEle.forEach(ele => {
      const preEle = document.createElement('pre')
      preEle.className = 'mermaid-src'
      preEle.hidden = true
      preEle.textContent = ele.textContent
      const newEle = document.createElement('div')
      newEle.className = 'mermaid-wrap'
      newEle.appendChild(preEle)
      ele.parentNode.replaceWith(newEle)
    })
  }

  const loadMermaid = () => {
    if (true) codeToMermaid()
    const $mermaid = document.querySelectorAll('#article-container .mermaid-wrap')
    if ($mermaid.length === 0) return

    const runMermaidFn = () => runMermaid($mermaid)
    btf.addGlobalFn('themeChange', runMermaidFn, 'mermaid')
    window.loadMermaid ? runMermaidFn() : btf.getScript('https://cdn.jsdelivr.net/npm/mermaid@11.12.1/dist/mermaid.min.js').then(runMermaidFn)
  }

  btf.addGlobalFn('encrypt', loadMermaid, 'mermaid')
  window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
})()</script></div><script async data-pjax src="/"></script></div></body></html>